{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOllama(model=\"llama3.2:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bed6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptProcessor:\n",
    "    \"\"\"處理音轉文本和摘要生成的主要類\"\"\"\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        \"\"\"預處理文本，移除冗餘內容並保留關鍵資訊\"\"\"\n",
    "        # 移除特殊符號和多餘空白\n",
    "        text = re.sub(r'[\\n\\t]+', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text) \n",
    "        text = text.strip()\n",
    "\n",
    "        # 移除常見的贅字贅語\n",
    "        removals = [\n",
    "            '請不吝點贊 訂閱 轉發 打賞支持明鏡與點點欄目',\n",
    "            '我們就明天早上8點半早晨財經速解讀再相見',\n",
    "            '祝各位投資朋友看盤順利操盤愉快'\n",
    "        ]\n",
    "        for r in removals:\n",
    "            text = text.replace(r, '')\n",
    "\n",
    "        return text\n",
    "\n",
    "    def split_segments(self, text: str) -> List[str]:\n",
    "        \"\"\"將文本分割成較小的片段\"\"\"\n",
    "        return self.text_splitter.split_text(text)\n",
    "\n",
    "    def generate_summary(self, segments: List[str]) -> str:\n",
    "        \"\"\"基於文本片段生成摘要\"\"\"\n",
    "        summaries = []\n",
    "        for seg in segments:\n",
    "            prompt = f\"請總結以下文字段落的重點:\\n{seg}\"\n",
    "            msg = HumanMessage(content=prompt)\n",
    "            response = self.llm.invoke([msg])\n",
    "            summaries.append(response.content)\n",
    "\n",
    "        # 合併並產生最終摘要\n",
    "        final_prompt = f\"請整合以下重點並產生300字以內的摘要:\\n{'\\n'.join(summaries)}\"\n",
    "        final_msg = HumanMessage(content=final_prompt)\n",
    "        final_summary = self.llm.invoke([final_msg])\n",
    "\n",
    "        return final_summary.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]  # 儲存對話訊息\n",
    "    transcript: str  # 儲存原始文本\n",
    "    processed_text: str  # 儲存預處理後的文本\n",
    "    segments: List[str]  # 儲存分段後的文本\n",
    "    summary: str  # 儲存最終摘要\n",
    "\n",
    "processor = TranscriptProcessor(llm)\n",
    "\n",
    "def preprocess(state: State):\n",
    "    \"\"\"預處理文本節點\"\"\"\n",
    "    text = state['transcript']\n",
    "    processed = processor.preprocess_text(text)\n",
    "    return {\"processed_text\": processed}\n",
    "\n",
    "def split_text(state: State):\n",
    "    \"\"\"分割文本節點\"\"\"\n",
    "    text = state['processed_text']\n",
    "    segments = processor.split_segments(text)\n",
    "    return {\"segments\": segments}\n",
    "\n",
    "def summarize(state: State):\n",
    "    \"\"\"生成摘要節點\"\"\"\n",
    "    segments = state['segments']\n",
    "    summary = processor.generate_summary(segments)\n",
    "    return {\"summary\": summary, \"messages\": [HumanMessage(content=summary)]}\n",
    "\n",
    "# 建立工作流程圖\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 添加節點\n",
    "graph_builder.add_node(\"preprocess\", preprocess)\n",
    "graph_builder.add_node(\"split\", split_text) \n",
    "graph_builder.add_node(\"summarize\", summarize)\n",
    "\n",
    "# 設定節點關係\n",
    "graph_builder.add_edge(START, \"preprocess\")\n",
    "graph_builder.add_edge(\"preprocess\", \"split\")\n",
    "graph_builder.add_edge(\"split\", \"summarize\")\n",
    "graph_builder.add_edge(\"summarize\", END)\n",
    "\n",
    "# 編譯工作流程\n",
    "chain = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 CSV 檔案\n",
    "df = pd.read_csv('../transcripts_video_v1.1.csv')\n",
    "\n",
    "# 處理第一個逐字稿作為示例\n",
    "sample_transcript = df['transcript'].iloc[0]\n",
    "\n",
    "# 執行工作流程\n",
    "result = chain.invoke({\n",
    "    \"transcript\": sample_transcript,\n",
    "    \"messages\": [],\n",
    "    \"processed_text\": \"\",\n",
    "    \"segments\": [],\n",
    "    \"summary\": \"\"\n",
    "})\n",
    "\n",
    "print(\"\\n最終摘要:\")\n",
    "print(\"-\" * 50)\n",
    "print(result[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f3478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(chain.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ef5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52d11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab284400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b381172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a0c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddebe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
